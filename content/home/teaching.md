+++
# Custom widget.
# An example of using the custom widget to create your own homepage section.
# To create more sections, duplicate this file and edit the values below as desired.
widget = "custom"
active = true
date = 2016-04-20T00:00:00

# Note: a full width section format can be enabled by commenting out the `title` and `subtitle` with a `#`.
title = "Teaching/Talks/Activities"
subtitle = ""

# Order that this section will appear in.
weight = 60

+++

Some miscellaneous  **notes and musings**:  [**Number Theory Meets Computability
Theory**](https://www.krichardson.me/files/h10.pdf) (see also
[*blog post*](https://www.krichardson.me/post/number_computability/));
other lecture notes: [**Notes on Language Models, Attention and
Transformers**](https://www.krichardson.me/files/lms.pdf),
[**Negation as Failure**](https://www.krichardson.me/files/naf.pdf),
[**Mixing Logic and Deep Learning: The `Logic as Loss Function`
Approach**](https://www.krichardson.me/files/logic_dl.pdf), [**Introduction to
Probability**](https://www.krichardson.me/files/probability.pdf).
[**Formal Techniques for Neural-symbolic Modeling**](https://github.com/yakazimir/esslli_neural_symbolic)
taught at [*ESSLLI
2023*](https://2023.esslli.eu/courses-workshops-accepted/course-information.html#1),
[**Language Model
Programming**](https://github.com/yakazimir/esslli_2024_llm_programming)
taught at [**ESSLLI 2024**](https://2024.esslli.eu/) 

**Recent Talks** from me and my extended group: Brief (10 minute) introduction to
  [**Natural Language Understanding (NLU) and Language Modeling**](https://www.krichardson.me/files/nlu_lm.pdf)
  (*intended for a non-technical audience*); Overview of my work on
  [**diagnostic testing of neural
  models**](https://www.krichardson.me/files/probing.pdf);
   [**Pushing the Limits of Rule Reasoning in
  Transformers**](https://www.krichardson.me/files/aaai_2022.pdf)
  (*AAAI 2022*),  [**Breakpoint
  Transformers**](https://www.krichardson.me/files/emnlp_teaser.pdf)
  (EMNLP 2022); [**Learning to Decompose**](https://www.krichardson.me/files/EMNLP22_com.pdf) (EMNLP 2022)  [**Decomposed Prompting**](https://www.krichardson.me/files/DecomposedPrompting.pdf)
  (ICLR 2023); [**Language Model Programming: Themes and
  Prospects**](https://www.krichardson.me/files/lm_programming.pdf) (*overview of my recent work, given at the University
  of Tuebingen*); [**Declarative Characterizations of Direct
  Preference Alignment
  Algorithms**](https://www.krichardson.me/files/declarative_alignment.pdf),
  [**Language Modeling by Language Models**](https://www.krichardson.me/files/genesys.pdf) (*recent work on
  automated scientific discovery, presented at the AI for scientific
  discovery workshop at NAACL, preprint forthcoming*)  
  
  **Recent News** 
  
- Released the [Open-Cot leaderboard](https://huggingface.co/spaces/logikon/open_cot_leaderboard)
  on Huggingface that aims to track model improvements due to
  chain-of-thought prompting. 

- **3 papers accepted to ACL 2024** on
  [**OLMO**](https://arxiv.org/abs/2402.00838), [**DOLMA**](https://arxiv.org/abs/2402.00159) (*our work on open-source
  large language models; both received best paper awards*) and [**TimeArena**](https://arxiv.org/abs/2402.05733) (agent
  modeling with time constraints). 
  
- Taught a class this summer at ESSLLI with [**Gijs
  Wijnholds**](https://gijswijnholds.github.io/) on [**Language Model
  Programming**](https://github.com/yakazimir/esslli_2024_llm_programming)
  (*our attempt to look at current NLP through the lens of conventional programming and programming theory*)

- **2 papers accepted at EMNLP 2024**: [**SUPER**](https://arxiv.org/pdf/2409.07440) (*LLM experiment
  agents; received outstanding paper award*), [**Event causality via Synthetic Control**](https://www.seas.upenn.edu/~why16gzl/Event_Causality_Identification_with_Synthetic_Control.pdf)
  (*novel causal analysis techniquee for detecting event causality*)

- **Papers at NeurIPS 2024** [**Paloma**](https://arxiv.org/pdf/2312.10523)
  (*LLM perplexity benchmarking*), [**Declarative Characterizations
  of direct preference alignment algorithms**](https://openreview.net/forum?id=SDtdKJBTcI) (*draft of
  recent work on formal characterizations of DPO, presented at [M3L](https://sites.google.com/view/m3l-2024/)
  workshop*), [**AucArena**](https://openreview.net/pdf?id=hKEzHiYJXc) (*work on
  environment for interactive agent modeling; presented at [OWA
  workshop](https://sites.google.com/view/open-world-agents/home)*), [**SelfGoal**](https://openreview.net/pdf?id=vrughWt2tr)
  (*work on memory architectures for interactive agents; presented at
  [OWA workshop](https://sites.google.com/view/open-world-agents/home)*)

- **Paper at NAACL 2025** [**SELFGOAL: Your Language Agents Already Know How to Achieve High-level Goals**](https://arxiv.org/pdf/2406.04784) (*LLM agent architectures*)

- **Two papers accepted at ICML 2025** [**Understanding the Logic of Direct Preference Alignment through Logic**](https://arxiv.org/abs/2412.17696) (*formal characterization
  of direct preference alignment algorithms*, [**brief overview**](https://www.krichardson.me/files/icml_preference_5min_slides.pdf)), [**ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning**](https://arxiv.org/pdf/2502.01100) (*hard reasoning
  problems for LLMs*)

- New talk on automated science discovery, [**Language Modeling by
  Language Models**](https://www.krichardson.me/files/genesys.pdf). Presented
  at the NAACL 2025 AISD workshop. Pre-print [**here**](https://arxiv.org/abs/2506.20249) 

- I taught another version of our [**Language Model Programming**](https://github.com/yakazimir/LMProgramming)
  course at ESSLLI 2025, with some new lectures on [*probabilistic
  programming for prompting*](https://github.com/yakazimir/LMProgramming/blob/main/slides/lecture5.pdf)
  and [*loss function decompilation*](https://github.com/yakazimir/LMProgramming/blob/main/slides/lecture3.pdf)
  (*both recent research topics of mine*). 

- I gave a keynote at the [NALOMA 2025
  workshop](https://naloma.github.io/2025/index.html) entitlted
  [**Understanding the Logic of Generative AI through Logic**](https://naloma.github.io/2025/slides/keynote-3.pdf)

- We released the [**astabench leaderboard**](https://huggingface.co/spaces/allenai/asta-bench-leaderboard),
  [technical  paper](https://www.datocms-assets.com/64837/1756485374-astabench-2025-08-29.pdf),
  a large initiative to comprehensively evaluate LLM agents across
  different science tasks. 

- **Paper accepted at EMNLP 2025** [**TinyScientist: An Interactive,
  Extensible, and Controllable Framework for Building Research Agents**](https://arxiv.org/pdf/2510.06579)
  (*library for LLM-driven automated research.*) 

- **Paper accepted at NeurIPS 2025** Our work on [**Language Modeling
  by Language Models**](https://github.com/yakazimir/esslli_2024_llm_programming)
  (*research agents for autonomous machine learning research*) was accepted as a spolight paper. 

- I gave an invited keynote at the [**International Workshop on
  Symbolic-Neural Learning (SNL2025)**](https://im.sanken.osaka-u.ac.jp/snl2025/) in Osaka  Japan. Slides are [here](https://www.krichardson.me/files/snl_2025.pdf). 

- Two papers accepted to **ICLR 2026**: [**AstaBench: Rigorous
  Benchmarking of AI Agents with a Holistic Scientific Research
  Suite**](https://www.datocms-assets.com/64837/1756485374-astabench-2025-08-29.pdf)
  (our work on LLM agent benchmarking), [**Analytica: Soft
  Propositional Reasoning for Robust and Scalable LLM-Driven
  Analysis**](https://openreview.net/forum?id=9cFT6u82uh&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2026%2FConference%2FAuthors%23your-submissions))
  (LLM agents for forecasting, formal analysis of agent systems; preprint coming soon)
